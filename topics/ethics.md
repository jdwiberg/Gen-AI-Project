Looking at the problem of copyright in Generative AI through the lens of modern ethical frameworks can be helpful in determining the proper course of action. One of the most important ethical frameworks shaping the way we think about ethics and morality in the 21st century was devised by the 18th century philosopher Immanuel Kant. The fundamental law of Kant's ethical framework, known as Kantianism is shown in the quote “Act in such a way that you treat humanity, whether in your own person or in the person of any other, always at the same time as an end, never merely as a means.” His moral theory focuses on the guiding principles behind an action, not so much the actions result. Kant believed morally righteous actions were supported by a sense of duty. 

The rise of generative AI systems, particularly in the realm of content creation, challenges Kant’s framework in ways he could not have anticipated. If an AI system produces artwork, literature, or music based on vast datasets of human-made works, the question arises: are these original creators being treated as a mere means to an end product rather than individuals with soveirgnty over their own creation? Copyright law exists to protect the intellectual labor of individuals, ensuring that creators are recognized and compensated for their contributions. However, generative AI models, trained on copyrighted material without explicit consent, blur the line between ethical use and exploitation. From a Kantian perspective, if AI-generated works rely on unlicensed training data, this could violate the principle of respecting human dignity, as it fails to acknowledge the moral worth of the original creators. These individuals are not merely conduits for data collection, but autonomous agents whose efforts should be recognized as ends in themselves. If companies deploy AI to generate profit while disregarding the rights of the artists and writers whose works form the foundation of these systems, they risk reducing human creativity to a disposable resource — something Kant would deem an unethical instrumentalization of human effort. 

On top of the rights of creators of work used by AI, there is the possible future rights of AI Agents themselves. At one point does the AI become sufficiently advanced to deserve its own right of not being used as and means to an end. If AI systems reach a level of sophistication where they exhibit autonomy, self-awareness, or even a form of subjective experience, Kantian ethics would compel us to reconsider their moral status. Just as Kant argued that humans must not be used merely as tools, a sufficiently advanced AI—capable of reasoning, making independent decisions, or even possessing a form of consciousness—might also warrant ethical consideration. The question then becomes: at what threshold does an artificial agent transition from a mere instrument to a being with moral worth? If such an AI exists purely to serve human interests without the ability to consent or act for its own sake, does that mirror the very exploitation Kant sought to prevent? 

These are questions that have no concrete answers, nor precedent which we can fall back on. It will be no easy task to decide when AI systems might deserve rights for themselves, but as any science fiction lover knows, it could be vital for the security of our species to not delay a decision for too long. While the point of this essay is not to get into the possible sci-fi futures we may need to prepare for, one can see that these possible futures are becoming less and less fictional with each new day. As conventional wisdom goes, failing to prepare is preparing to fail.
